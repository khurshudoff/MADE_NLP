{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13pL--6rycN3"
   },
   "source": [
    "## Dealing with texts using CNN\n",
    "\n",
    "Today we're gonna apply the newly learned tools for the task of predicting job salary.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/3342/logos/front_page.png\" width=400px>\n",
    "\n",
    "Based on YSDA [materials](https://github.com/yandexdataschool/nlp_course/blob/master/week02_classification/seminar.ipynb). _Special thanks to [Oleg Vasilev](https://github.com/Omrigan/) for the core assignment idea._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8zS7m-gycN5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "34x92vWQycN_"
   },
   "source": [
    "### About the challenge\n",
    "For starters, let's download and unpack the data from [here](https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=0). \n",
    "\n",
    "You can also get it from [yadisk url](https://yadi.sk/d/vVEOWPFY3NruT7) the competition [page](https://www.kaggle.com/c/job-salary-prediction/data) (pick `Train_rev1.*`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "vwN72gd4ycOA",
    "outputId": "b918d846-6e4f-4107-eb00-a3439494fc2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  119M  100  119M    0     0  24.8M      0  0:00:04  0:00:04 --:--:-- 35.4M\n",
      "Train_rev1.csv\n"
     ]
    }
   ],
   "source": [
    "# Do this only once\n",
    "!curl -L https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1 -o Train_rev1.csv.tar.gz\n",
    "!tar -xvzf ./Train_rev1.csv.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NKRssfWJUrsg",
    "outputId": "743fcec0-0c11-460b-d548-f968a79e1317"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244768, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "PkpTo9OAUrsl",
    "outputId": "142ad181-f73a-47d9-f1cc-bb556d58c41a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12612844</td>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 40000/annum 20-40K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12613049</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
       "      <td>27500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12613647</td>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  ...        SourceName\n",
       "0  12612628  ...  cv-library.co.uk\n",
       "1  12612830  ...  cv-library.co.uk\n",
       "2  12612844  ...  cv-library.co.uk\n",
       "3  12613049  ...  cv-library.co.uk\n",
       "4  12613647  ...  cv-library.co.uk\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z7kznuJfycOH"
   },
   "source": [
    "One problem with salary prediction is that it's oddly distributed: there are many people who are paid standard salaries and a few that get tons o money. The distribution is fat-tailed on the right side, which is inconvenient for MSE minimization.\n",
    "\n",
    "There are several techniques to combat this: using a different loss function, predicting log-target instead of raw target or even replacing targets with their percentiles among all salaries in the training set. We gonna use logarithm for now.\n",
    "\n",
    "_You can read more [in the official description](https://www.kaggle.com/c/job-salary-prediction#description)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "UuuKIKfrycOH",
    "outputId": "dd653937-b32e-462a-c185-51c5b2addeeb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data[\"SalaryNormalized\"], bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(data['Log1pSalary'], bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fcu-qmHRycOK"
   },
   "source": [
    "Our task is to predict one number, __Log1pSalary__.\n",
    "\n",
    "To do so, our model can access a number of features:\n",
    "* Free text: __`Title`__ and  __`FullDescription`__\n",
    "* Categorical: __`Category`__, __`Company`__, __`LocationNormalized`__, __`ContractType`__, and __`ContractTime`__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "colab_type": "code",
    "id": "p9vyA_erycOK",
    "outputId": "7dffe778-5e48-41ce-8255-c8ce9fb6787b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "      <th>Log1pSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149177</th>\n",
       "      <td>70762211</td>\n",
       "      <td>Primary Teachers</td>\n",
       "      <td>AMDAS EDUCATION (Apply online only) Our Primar...</td>\n",
       "      <td>Penge, London</td>\n",
       "      <td>Penge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contract</td>\n",
       "      <td>Amdas Consultancy Ltd</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>115 - 145/day MPS when taken on permanent +Bonus</td>\n",
       "      <td>31200</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "      <td>10.348206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>53007687</td>\n",
       "      <td>RGN Enduring Mental Illness (Care Home)</td>\n",
       "      <td>We are currently recruiting for an experienced...</td>\n",
       "      <td>Haslemere, Surrey</td>\n",
       "      <td>Haslemere</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Healthcare &amp; Nursing Jobs</td>\n",
       "      <td>26000 to 26000 per year</td>\n",
       "      <td>26000</td>\n",
       "      <td>careworx.co.uk</td>\n",
       "      <td>10.165891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57513</th>\n",
       "      <td>68685610</td>\n",
       "      <td>Business Development Executive  Dunfermline, Fife</td>\n",
       "      <td>TribePost Ltd are working on behalf of our cli...</td>\n",
       "      <td>Dunfermline Fife Scotland</td>\n",
       "      <td>Dunfermline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Tribepost Ltd</td>\n",
       "      <td>Sales Jobs</td>\n",
       "      <td>Up to 20,000 per annum plus an attractive comm...</td>\n",
       "      <td>20000</td>\n",
       "      <td>totaljobs.com</td>\n",
       "      <td>9.903538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id  ... Log1pSalary\n",
       "149177  70762211  ...   10.348206\n",
       "2160    53007687  ...   10.165891\n",
       "57513   68685610  ...    9.903538\n",
       "\n",
       "[3 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "target_column = \"Log1pSalary\"\n",
    "\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
    "\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IUdclucmycON"
   },
   "source": [
    "### Preprocessing text data\n",
    "\n",
    "Just like last week, applying NLP to a problem begins from tokenization: splitting raw text into sequences of tokens (words, punctuation, etc).\n",
    "\n",
    "__Your task__ is to lowercase and tokenize all texts under `Title` and `FullDescription` columns. Store the tokenized data as a __space-separated__ string of tokens for performance reasons.\n",
    "\n",
    "It's okay to use nltk tokenizers. Assertions were designed for WordPunctTokenizer, slight deviations are okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "YzeOxD_aycOO",
    "outputId": "7b953df4-e153-478b-a229-76d7f163fa4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text:\n",
      "2         Mathematical Modeller / Simulation Analyst / O...\n",
      "100002    A successful and high achieving specialist sch...\n",
      "200002    Web Designer  HTML, CSS, JavaScript, Photoshop...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw text:\")\n",
    "print(data[\"FullDescription\"][2::100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RUWkpd7PycOQ"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "\n",
    "# see task above\n",
    "def normalize(text):\n",
    "    # <YOUR CODE HERE>\n",
    "    text = str(text).lower()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return ' '.join(tokens)\n",
    "    \n",
    "data[text_columns] = data[text_columns].applymap(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o3pQdHihycOT"
   },
   "source": [
    "Now we can assume that our text is a space-separated list of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Gs-6lnS_ycOU",
    "outputId": "cdfeb7bc-a1e4-4fbc-ce70-0e807e3b1f65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized:\n",
      "2         mathematical modeller / simulation analyst / o...\n",
      "100002    a successful and high achieving specialist sch...\n",
      "200002    web designer html , css , javascript , photosh...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenized:\")\n",
    "print(data[\"FullDescription\"][2::100000])\n",
    "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
    "assert data[\"Title\"][54321] == 'international digital account manager ( german )'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ouE3L2hyycOX"
   },
   "source": [
    "Not all words are equally useful. Some of them are typos or rare words that are only present a few times. \n",
    "\n",
    "Let's count how many times is each word present in the data so that we can build a \"white list\" of known words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p1cd6vd5Urs9",
    "outputId": "f797dcd1-f6cb-4ef2-f737-90435f162900"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489536/489536 [00:15<00:00, 31449.07it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "token_counts = Counter() # <YOUR CODE HERE>\n",
    "for row in tqdm(data[text_columns].values.flatten()):\n",
    "    token_counts.update(row.split())\n",
    "\n",
    "# hint: you may or may not want to use collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "GiOWbc15ycOb",
    "outputId": "e93bb114-b46f-49f6-d54c-25bb390c4b1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens : 202704\n",
      "('and', 2657388)\n",
      "('.', 2523216)\n",
      "(',', 2318606)\n",
      "('the', 2080994)\n",
      "('to', 2019884)\n",
      "...\n",
      "('stephanietraveltraderecruitmnt', 1)\n",
      "('ruabon', 1)\n",
      "('lowehays', 1)\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
    "\n",
    "assert token_counts.most_common(1)[0][1] in  range(2600000, 2700000)\n",
    "assert len(token_counts) in range(200000, 210000)\n",
    "print('Correct!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "nd5v3BNfycOf",
    "outputId": "92818bad-b607-4f71-e92c-8d0acdc0ee68"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see how many words are there for each count\n",
    "plt.hist(list(token_counts.values()), range=[0, 10**4], bins=50, log=True)\n",
    "plt.xlabel(\"Word counts\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znuXxeghycOh"
   },
   "source": [
    "Now filter tokens a list of all tokens that occur at least 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RoL2DAsJUrtD",
    "outputId": "32686ba7-1495-448b-adf4-d32dfc37a6c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202704"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SeNFBWx5ycOh"
   },
   "outputs": [],
   "source": [
    "min_count = 10\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = [token for token, count in token_counts.items() if count >= min_count] # <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RATIRyPKycOk",
    "outputId": "09c3b4c1-385e-4b89-9cc6-605f57c8406c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 34158\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + sorted(tokens)\n",
    "print(\"Vocabulary size:\", len(tokens))\n",
    "\n",
    "assert type(tokens) == list\n",
    "assert len(tokens) in range(32000, 35000)\n",
    "assert 'me' in tokens\n",
    "assert UNK in tokens\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cqEsgbjZycOo"
   },
   "source": [
    "Build an inverse token index: a dictionary from token(string) to it's index in `tokens` (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L60lo1l_ycOq"
   },
   "outputs": [],
   "source": [
    "# You have already done that ;)\n",
    "\n",
    "token_to_id = {token: idx for idx, token in enumerate(tokens)} # <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DeAoVo4mycOr",
    "outputId": "00cfb24e-7931-4df3-9830-5e79e64b6bb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(token_to_id, dict)\n",
    "assert len(token_to_id) == len(tokens)\n",
    "for tok in tokens:\n",
    "    assert tokens[token_to_id[tok]] == tok\n",
    "\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cmJAkq3gycOv"
   },
   "source": [
    "And finally, let's use the vocabulary you've built to map text lines into neural network-digestible matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEsLeBjVycOw"
   },
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "JiBlPkdKycOy",
    "outputId": "2f2c5749-c2ce-4a20-c5c4-59e439c050c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines:\n",
      "engineering systems analyst\n",
      "hr assistant\n",
      "senior ec & i engineer\n",
      "\n",
      "Matrix:\n",
      "[[10807 30161  2166     1     1]\n",
      " [15020  2844     1     1     1]\n",
      " [27645 10201    16 15215 10804]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lines:\")\n",
    "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(data[\"Title\"][::100000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nGOdZ3-dycO4"
   },
   "source": [
    "Now let's  encode the categirical data we have.\n",
    "\n",
    "As usual, we shall use one-hot encoding for simplicity. Kudos if you implement more advanced encodings: tf-idf, pseudo-time-series, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "DpOlBp7ZycO6",
    "outputId": "1105d5c5-1209-41b1-f423-5e5487eca5f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, separator='=', sort=True,\n",
       "               sparse=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yk4jmtAYycO8"
   },
   "source": [
    "### The deep learning part\n",
    "\n",
    "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
    "\n",
    "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
    "\n",
    "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "TngLcWA0ycO_",
    "outputId": "1c902da7-850b-4ee7-d4d5-2165fb919bad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  195814\n",
      "Validation size =  48954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PXuKgOSycPB"
   },
   "outputs": [],
   "source": [
    "def make_batch(data, max_len=None, word_dropout=0):\n",
    "    \"\"\"\n",
    "    Creates a keras-friendly dict from the batch data.\n",
    "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "    \n",
    "    if target_column in data.columns:\n",
    "        batch[target_column] = data[target_column].values\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I6LpEQf0ycPD"
   },
   "outputs": [],
   "source": [
    "a = make_batch(data_train[:3], max_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eI5h9UMycPF"
   },
   "source": [
    "#### Architecture\n",
    "\n",
    "Our main model consists of three branches:\n",
    "* Title encoder\n",
    "* Description encoder\n",
    "* Categorical features encoder\n",
    "\n",
    "We will then feed all 3 branches into one common network that predicts salary.\n",
    "\n",
    "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
    "\n",
    "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GuYsbWo3Urta"
   },
   "source": [
    "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J0wnZOS0Urta"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iseA5qMDUrtb"
   },
   "outputs": [],
   "source": [
    "# You will need these to make it simple\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Reorder(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.permute((0, 2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEQ9aVXXUrtc"
   },
   "source": [
    "To generate minibatches we will use simple pyton generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CTRaOx3IUrtc"
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
    "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
    "            target = batch.pop(target_column)\n",
    "            yield batch, target\n",
    "        \n",
    "        if not cycle: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PSJF5jQUUrte"
   },
   "outputs": [],
   "source": [
    "iterator = iterate_minibatches(data_train, 3)\n",
    "batch, target = next(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6ufO_5iUrt-"
   },
   "source": [
    "### Bonus area: three-headed network.\n",
    "\n",
    "Now you can try to implement the network we've discussed above. Use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9axzT6-tk9aG"
   },
   "outputs": [],
   "source": [
    "class ThreeInputsNet(nn.Module):\n",
    "  def __init__(self, n_tokens, n_cat_features, hid_size = 64, n_max = 2):\n",
    "    super(self.__class__, self).__init__()\n",
    "    self.emb1 = nn.Embedding(\n",
    "        num_embeddings = n_tokens,\n",
    "        embedding_dim = hid_size\n",
    "    )\n",
    "    self.reorder1 = Reorder()\n",
    "    self.conv1_1 = nn.Conv1d(\n",
    "        in_channels = hid_size,\n",
    "        out_channels = hid_size,\n",
    "        kernel_size = 3\n",
    "    )\n",
    "    self.relu1_1 = nn.ReLU()\n",
    "    self.conv1_2 = nn.Conv1d(\n",
    "        in_channels=hid_size,\n",
    "        out_channels=hid_size,\n",
    "        kernel_size=4\n",
    "    )\n",
    "    self.bn1 = nn.BatchNorm1d(hid_size)\n",
    "    self.relu1_2 = nn.ReLU()\n",
    "    self.adaptive_pool1 = nn.AdaptiveMaxPool1d(output_size=n_max)\n",
    "    self.flatten1 = nn.Flatten()\n",
    "    # self.linear1 = nn.Linear(hid_size * n_max, 1)\n",
    "\n",
    "    self.emb2 = nn.Embedding(\n",
    "        num_embeddings = n_tokens,\n",
    "        embedding_dim=hid_size,\n",
    "    )\n",
    "    self.reorder2 = Reorder()\n",
    "    self.conv2_1 = nn.Conv1d(\n",
    "        in_channels=hid_size,\n",
    "        out_channels=hid_size,\n",
    "        kernel_size=3\n",
    "    )\n",
    "    self.relu2_1 = nn.ReLU()\n",
    "    self.conv2_2 = nn.Conv1d(\n",
    "        in_channels=hid_size,\n",
    "        out_channels=hid_size,\n",
    "        kernel_size=4\n",
    "    )\n",
    "    self.bn2 = nn.BatchNorm1d(hid_size)\n",
    "    self.relu2_2 = nn.ReLU()\n",
    "    self.adaptive_pool2 = nn.AdaptiveMaxPool1d(output_size=n_max)\n",
    "    self.flatten2 = nn.Flatten()\n",
    "    # self.linear2 = nn.Linear(hid_size * n_max, 1)\n",
    "\n",
    "    self.linear3 = nn.Linear(n_cat_features, hid_size * n_max)\n",
    "\n",
    "    self.linear123 = nn.Linear(hid_size * n_max + hid_size * n_max + hid_size * n_max, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    full_descr, title, cat_features = x\n",
    "\n",
    "    full_descr = self.emb1(full_descr)\n",
    "    full_descr = self.reorder1(full_descr)\n",
    "    full_descr = self.conv1_1(full_descr)\n",
    "    full_descr = self.relu1_1(full_descr)\n",
    "    full_descr = self.conv1_2(full_descr)\n",
    "    full_descr = self.bn1(full_descr)\n",
    "    full_descr = self.relu1_2(full_descr)\n",
    "    full_descr = self.adaptive_pool1(full_descr)\n",
    "    full_descr = self.flatten1(full_descr)\n",
    "    # full_descr = self.linear1(full_descr)\n",
    "\n",
    "    title = self.emb1(title)\n",
    "    title = self.reorder1(title)\n",
    "    title = self.conv1_1(title)\n",
    "    title = self.relu1_1(title)\n",
    "    title = self.conv1_2(title)\n",
    "    title = self.bn1(title)\n",
    "    title = self.relu1_2(title)\n",
    "    title = self.adaptive_pool1(title)\n",
    "    title = self.flatten1(title)\n",
    "    # title = self.linear1(title)\n",
    "\n",
    "    cat_features = self.linear3(cat_features)\n",
    "\n",
    "    x = torch.cat((full_descr, title, cat_features), dim=1)\n",
    "    x = self.linear123(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yi-zzZV3fIOX"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "n_tokens=len(tokens)\n",
    "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
    "hid_size=64\n",
    "n_max = 2\n",
    "epochs = 2\n",
    "\n",
    "model = ThreeInputsNet(n_tokens=len(tokens), n_cat_features=n_cat_features, hid_size=64)\n",
    "model = model.to(device)\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.MSELoss() # <YOUR CODE HERE>\n",
    "lr_sched = ReduceLROnPlateau(opt, factor=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNhtQrsyhchF"
   },
   "outputs": [],
   "source": [
    "batch, _ = next(iterate_minibatches(data_train))\n",
    "batch = (\n",
    "    torch.tensor(batch['FullDescription'], dtype=torch.long).to(device),\n",
    "    torch.tensor(batch['Title'], dtype=torch.long).to(device),\n",
    "    torch.tensor(batch['Categorical'], dtype=torch.float).to(device)\n",
    ")\n",
    "predictions = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "-RAKdCL5ra0X",
    "outputId": "7cb25194-8507-4cf2-fead-925797caa637"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "history = []\n",
    "for epoch_num in range(epochs):\n",
    "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
    "        # Preprocessing the batch data and target\n",
    "        batch = (\n",
    "            torch.tensor(batch['FullDescription'], dtype=torch.long).to(device),\n",
    "            torch.tensor(batch['Title'], dtype=torch.long).to(device),\n",
    "            torch.tensor(batch['Categorical'], dtype=torch.float).to(device)\n",
    "        )\n",
    "        target = torch.tensor(target).to(device)\n",
    "\n",
    "        predictions = model(batch)\n",
    "        predictions = predictions.view(predictions.size(0))\n",
    "\n",
    "        loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
    "\n",
    "        # train with backprop\n",
    "        # <YOUR CODE HERE>\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        history.append(loss)\n",
    "        if (idx+1)%10==0:\n",
    "            clear_output(True)\n",
    "            plt.plot(history[15:],label='loss')\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BozcdmDozXhB",
    "outputId": "87404f00-ca02-43ad-9c64-48b5f364881d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kEbVOxsuraiM",
    "outputId": "e5ddfeb7-66ea-4f2f-fcbe-fea04cc49dac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3it [00:00, 23.77it/s]\u001b[A\n",
      "6it [00:00, 23.28it/s]\u001b[A\n",
      "9it [00:00, 22.82it/s]\u001b[A\n",
      "12it [00:00, 22.70it/s]\u001b[A\n",
      "15it [00:00, 22.55it/s]\u001b[A\n",
      "18it [00:00, 22.70it/s]\u001b[A\n",
      "21it [00:00, 22.46it/s]\u001b[A\n",
      "24it [00:01, 22.24it/s]\u001b[A\n",
      "27it [00:01, 21.12it/s]\u001b[A\n",
      "30it [00:01, 21.26it/s]\u001b[A\n",
      "33it [00:01, 21.29it/s]\u001b[A\n",
      "36it [00:01, 21.54it/s]\u001b[A\n",
      "39it [00:01, 21.35it/s]\u001b[A\n",
      "42it [00:01, 21.26it/s]\u001b[A\n",
      "45it [00:02, 21.32it/s]\u001b[A\n",
      "48it [00:02, 21.22it/s]\u001b[A\n",
      "51it [00:02, 21.14it/s]\u001b[A\n",
      "54it [00:02, 21.41it/s]\u001b[A\n",
      "57it [00:02, 21.67it/s]\u001b[A\n",
      "60it [00:02, 21.80it/s]\u001b[A\n",
      "63it [00:02, 22.03it/s]\u001b[A\n",
      "66it [00:03, 21.57it/s]\u001b[A\n",
      "69it [00:03, 21.50it/s]\u001b[A\n",
      "72it [00:03, 20.74it/s]\u001b[A\n",
      "75it [00:03, 20.90it/s]\u001b[A\n",
      "78it [00:03, 20.56it/s]\u001b[A\n",
      "81it [00:03, 20.63it/s]\u001b[A\n",
      "84it [00:03, 20.48it/s]\u001b[A\n",
      "87it [00:04, 20.43it/s]\u001b[A\n",
      "90it [00:04, 20.35it/s]\u001b[A\n",
      "93it [00:04, 19.82it/s]\u001b[A\n",
      "95it [00:04, 19.33it/s]\u001b[A\n",
      "97it [00:04, 19.45it/s]\u001b[A\n",
      "100it [00:04, 19.91it/s]\u001b[A\n",
      "102it [00:04, 19.42it/s]\u001b[A\n",
      "104it [00:04, 19.17it/s]\u001b[A\n",
      "106it [00:05, 18.72it/s]\u001b[A\n",
      "108it [00:05, 18.79it/s]\u001b[A\n",
      "110it [00:05, 18.44it/s]\u001b[A\n",
      "113it [00:05, 18.69it/s]\u001b[A\n",
      "115it [00:05, 17.97it/s]\u001b[A\n",
      "117it [00:05, 18.12it/s]\u001b[A\n",
      "119it [00:05, 17.84it/s]\u001b[A\n",
      "121it [00:05, 17.91it/s]\u001b[A\n",
      "123it [00:06, 18.08it/s]\u001b[A\n",
      "125it [00:06, 18.60it/s]\u001b[A\n",
      "127it [00:06, 18.66it/s]\u001b[A\n",
      "129it [00:06, 18.71it/s]\u001b[A\n",
      "132it [00:06, 19.18it/s]\u001b[A\n",
      "134it [00:06, 19.18it/s]\u001b[A\n",
      "137it [00:06, 19.49it/s]\u001b[A\n",
      "139it [00:06, 19.50it/s]\u001b[A\n",
      "142it [00:06, 19.96it/s]\u001b[A\n",
      "145it [00:07, 20.08it/s]\u001b[A\n",
      "148it [00:07, 19.78it/s]\u001b[A\n",
      "150it [00:07, 19.10it/s]\u001b[A\n",
      "153it [00:07, 19.53it/s]\u001b[A\n",
      "156it [00:07, 19.58it/s]\u001b[A\n",
      "158it [00:07, 19.63it/s]\u001b[A\n",
      "160it [00:07, 18.76it/s]\u001b[A\n",
      "163it [00:08, 19.50it/s]\u001b[A\n",
      "165it [00:08, 19.39it/s]\u001b[A\n",
      "167it [00:08, 19.00it/s]\u001b[A\n",
      "169it [00:08, 18.60it/s]\u001b[A\n",
      "171it [00:08, 18.87it/s]\u001b[A\n",
      "173it [00:08, 19.00it/s]\u001b[A\n",
      "175it [00:08, 18.80it/s]\u001b[A\n",
      "178it [00:08, 19.36it/s]\u001b[A\n",
      "180it [00:08, 19.25it/s]\u001b[A\n",
      "183it [00:09, 19.50it/s]\u001b[A\n",
      "185it [00:09, 19.20it/s]\u001b[A\n",
      "187it [00:09, 19.07it/s]\u001b[A\n",
      "189it [00:09, 19.02it/s]\u001b[A\n",
      "191it [00:09, 17.65it/s]\u001b[A\n",
      "194it [00:09, 18.53it/s]\u001b[A\n",
      "196it [00:09, 18.90it/s]\u001b[A\n",
      "199it [00:09, 19.29it/s]\u001b[A\n",
      "202it [00:10, 19.93it/s]\u001b[A\n",
      "205it [00:10, 19.81it/s]\u001b[A\n",
      "207it [00:10, 19.27it/s]\u001b[A\n",
      "209it [00:10, 19.39it/s]\u001b[A\n",
      "211it [00:10, 19.49it/s]\u001b[A\n",
      "213it [00:10, 19.20it/s]\u001b[A\n",
      "215it [00:10, 19.02it/s]\u001b[A\n",
      "217it [00:10, 19.05it/s]\u001b[A\n",
      "219it [00:10, 19.07it/s]\u001b[A\n",
      "222it [00:11, 19.43it/s]\u001b[A\n",
      "224it [00:11, 19.28it/s]\u001b[A\n",
      "226it [00:11, 19.01it/s]\u001b[A\n",
      "228it [00:11, 18.60it/s]\u001b[A\n",
      "230it [00:11, 18.62it/s]\u001b[A\n",
      "232it [00:11, 18.86it/s]\u001b[A\n",
      "234it [00:11, 19.17it/s]\u001b[A\n",
      "236it [00:11, 19.06it/s]\u001b[A\n",
      "238it [00:11, 18.88it/s]\u001b[A\n",
      "241it [00:12, 19.27it/s]\u001b[A\n",
      "243it [00:12, 18.80it/s]\u001b[A\n",
      "245it [00:12, 18.68it/s]\u001b[A\n",
      "247it [00:12, 18.31it/s]\u001b[A\n",
      "250it [00:12, 18.93it/s]\u001b[A\n",
      "252it [00:12, 19.11it/s]\u001b[A\n",
      "254it [00:12, 19.27it/s]\u001b[A\n",
      "257it [00:12, 19.98it/s]\u001b[A\n",
      "260it [00:13, 20.00it/s]\u001b[A\n",
      "263it [00:13, 19.50it/s]\u001b[A\n",
      "266it [00:13, 19.88it/s]\u001b[A\n",
      "268it [00:13, 19.54it/s]\u001b[A\n",
      "270it [00:13, 19.55it/s]\u001b[A\n",
      "272it [00:13, 19.30it/s]\u001b[A\n",
      "274it [00:13, 19.35it/s]\u001b[A\n",
      "276it [00:13, 19.39it/s]\u001b[A\n",
      "278it [00:14, 19.11it/s]\u001b[A\n",
      "280it [00:14, 19.34it/s]\u001b[A\n",
      "283it [00:14, 19.45it/s]\u001b[A\n",
      "285it [00:14, 19.57it/s]\u001b[A\n",
      "287it [00:14, 17.72it/s]\u001b[A\n",
      "289it [00:14, 18.16it/s]\u001b[A\n",
      "291it [00:14, 18.65it/s]\u001b[A\n",
      "293it [00:14, 18.73it/s]\u001b[A\n",
      "295it [00:14, 18.72it/s]\u001b[A\n",
      "297it [00:15, 18.56it/s]\u001b[A\n",
      "300it [00:15, 18.81it/s]\u001b[A\n",
      "302it [00:15, 18.98it/s]\u001b[A\n",
      "305it [00:15, 19.38it/s]\u001b[A\n",
      "307it [00:15, 19.18it/s]\u001b[A\n",
      "309it [00:15, 19.25it/s]\u001b[A\n",
      "311it [00:15, 19.20it/s]\u001b[A\n",
      "314it [00:15, 19.51it/s]\u001b[A\n",
      "316it [00:16, 19.20it/s]\u001b[A\n",
      "319it [00:16, 19.38it/s]\u001b[A\n",
      "321it [00:16, 19.01it/s]\u001b[A\n",
      "324it [00:16, 19.56it/s]\u001b[A\n",
      "327it [00:16, 19.94it/s]\u001b[A\n",
      "330it [00:16, 19.88it/s]\u001b[A\n",
      "332it [00:16, 19.83it/s]\u001b[A\n",
      "334it [00:16, 19.51it/s]\u001b[A\n",
      "337it [00:17, 20.04it/s]\u001b[A\n",
      "340it [00:17, 19.04it/s]\u001b[A\n",
      "343it [00:17, 19.47it/s]\u001b[A\n",
      "345it [00:17, 18.58it/s]\u001b[A\n",
      "347it [00:17, 18.54it/s]\u001b[A\n",
      "349it [00:17, 18.77it/s]\u001b[A\n",
      "352it [00:17, 19.16it/s]\u001b[A\n",
      "355it [00:17, 19.64it/s]\u001b[A\n",
      "357it [00:18, 19.26it/s]\u001b[A\n",
      "359it [00:18, 19.12it/s]\u001b[A\n",
      "361it [00:18, 18.90it/s]\u001b[A\n",
      "364it [00:18, 19.48it/s]\u001b[A\n",
      "366it [00:18, 18.73it/s]\u001b[A\n",
      "368it [00:18, 18.67it/s]\u001b[A\n",
      "370it [00:18, 18.75it/s]\u001b[A\n",
      "372it [00:18, 18.50it/s]\u001b[A\n",
      "374it [00:19, 18.71it/s]\u001b[A\n",
      "377it [00:19, 19.08it/s]\u001b[A\n",
      "379it [00:19, 18.62it/s]\u001b[A\n",
      "381it [00:19, 18.32it/s]\u001b[A\n",
      "383it [00:19, 18.54it/s]\u001b[A\n",
      "385it [00:19, 18.29it/s]\u001b[A\n",
      "387it [00:19, 18.63it/s]\u001b[A\n",
      "389it [00:19, 19.00it/s]\u001b[A\n",
      "391it [00:19, 19.22it/s]\u001b[A\n",
      "393it [00:20, 19.14it/s]\u001b[A\n",
      "395it [00:20, 19.08it/s]\u001b[A\n",
      "397it [00:20, 19.11it/s]\u001b[A\n",
      "399it [00:20, 18.85it/s]\u001b[A\n",
      "401it [00:20, 18.97it/s]\u001b[A\n",
      "403it [00:20, 18.77it/s]\u001b[A\n",
      "405it [00:20, 18.82it/s]\u001b[A\n",
      "407it [00:20, 18.70it/s]\u001b[A\n",
      "409it [00:20, 18.92it/s]\u001b[A\n",
      "411it [00:20, 19.09it/s]\u001b[A\n",
      "413it [00:21, 19.34it/s]\u001b[A\n",
      "415it [00:21, 19.04it/s]\u001b[A\n",
      "417it [00:21, 19.30it/s]\u001b[A\n",
      "419it [00:21, 19.49it/s]\u001b[A\n",
      "422it [00:21, 20.03it/s]\u001b[A\n",
      "425it [00:21, 19.94it/s]\u001b[A\n",
      "427it [00:21, 19.26it/s]\u001b[A\n",
      "429it [00:21, 19.26it/s]\u001b[A\n",
      "431it [00:21, 19.10it/s]\u001b[A\n",
      "434it [00:22, 19.62it/s]\u001b[A\n",
      "437it [00:22, 19.93it/s]\u001b[A\n",
      "439it [00:22, 19.74it/s]\u001b[A\n",
      "441it [00:22, 19.01it/s]\u001b[A\n",
      "443it [00:22, 18.78it/s]\u001b[A\n",
      "446it [00:22, 19.23it/s]\u001b[A\n",
      "449it [00:22, 19.73it/s]\u001b[A\n",
      "452it [00:23, 19.68it/s]\u001b[A\n",
      "454it [00:23, 19.58it/s]\u001b[A\n",
      "456it [00:23, 19.37it/s]\u001b[A\n",
      "458it [00:23, 18.46it/s]\u001b[A\n",
      "460it [00:23, 18.35it/s]\u001b[A\n",
      "462it [00:23, 18.62it/s]\u001b[A\n",
      "464it [00:23, 17.95it/s]\u001b[A\n",
      "467it [00:23, 18.87it/s]\u001b[A\n",
      "469it [00:23, 18.99it/s]\u001b[A\n",
      "471it [00:24, 19.27it/s]\u001b[A\n",
      "473it [00:24, 19.26it/s]\u001b[A\n",
      "475it [00:24, 18.59it/s]\u001b[A\n",
      "477it [00:24, 18.63it/s]\u001b[A\n",
      "479it [00:24, 18.24it/s]\u001b[A\n",
      "482it [00:24, 18.96it/s]\u001b[A\n",
      "485it [00:24, 19.52it/s]\u001b[A\n",
      "487it [00:24, 18.99it/s]\u001b[A\n",
      "489it [00:25, 18.34it/s]\u001b[A\n",
      "491it [00:25, 18.60it/s]\u001b[A\n",
      "493it [00:25, 18.85it/s]\u001b[A\n",
      "496it [00:25, 19.20it/s]\u001b[A\n",
      "498it [00:25, 18.74it/s]\u001b[A\n",
      "500it [00:25, 18.62it/s]\u001b[A\n",
      "502it [00:25, 18.50it/s]\u001b[A\n",
      "504it [00:25, 18.21it/s]\u001b[A\n",
      "506it [00:25, 18.15it/s]\u001b[A\n",
      "509it [00:26, 18.91it/s]\u001b[A\n",
      "512it [00:26, 18.53it/s]\u001b[A\n",
      "514it [00:26, 18.87it/s]\u001b[A\n",
      "516it [00:26, 19.11it/s]\u001b[A\n",
      "519it [00:26, 19.55it/s]\u001b[A\n",
      "521it [00:26, 19.34it/s]\u001b[A\n",
      "523it [00:26, 18.92it/s]\u001b[A\n",
      "525it [00:26, 19.06it/s]\u001b[A\n",
      "527it [00:27, 19.18it/s]\u001b[A\n",
      "530it [00:27, 19.66it/s]\u001b[A\n",
      "533it [00:27, 20.12it/s]\u001b[A\n",
      "536it [00:27, 20.22it/s]\u001b[A\n",
      "539it [00:27, 20.13it/s]\u001b[A\n",
      "542it [00:27, 20.14it/s]\u001b[A\n",
      "545it [00:27, 19.73it/s]\u001b[A\n",
      "547it [00:28, 19.13it/s]\u001b[A\n",
      "549it [00:28, 18.57it/s]\u001b[A\n",
      "551it [00:28, 18.63it/s]\u001b[A\n",
      "553it [00:28, 18.49it/s]\u001b[A\n",
      "555it [00:28, 18.64it/s]\u001b[A\n",
      "558it [00:28, 19.28it/s]\u001b[A\n",
      "560it [00:28, 19.26it/s]\u001b[A\n",
      "562it [00:28, 19.21it/s]\u001b[A\n",
      "565it [00:28, 19.55it/s]\u001b[A\n",
      "568it [00:29, 20.00it/s]\u001b[A\n",
      "571it [00:29, 19.54it/s]\u001b[A\n",
      "573it [00:29, 19.32it/s]\u001b[A\n",
      "575it [00:29, 18.64it/s]\u001b[A\n",
      "578it [00:29, 18.22it/s]\u001b[A\n",
      "580it [00:29, 18.61it/s]\u001b[A\n",
      "582it [00:29, 18.81it/s]\u001b[A\n",
      "585it [00:29, 19.63it/s]\u001b[A\n",
      "587it [00:30, 18.88it/s]\u001b[A\n",
      "589it [00:30, 18.95it/s]\u001b[A\n",
      "591it [00:30, 18.97it/s]\u001b[A\n",
      "593it [00:30, 18.80it/s]\u001b[A\n",
      "596it [00:30, 19.32it/s]\u001b[A\n",
      "598it [00:30, 18.68it/s]\u001b[A\n",
      "600it [00:30, 18.18it/s]\u001b[A\n",
      "602it [00:30, 18.15it/s]\u001b[A\n",
      "604it [00:31, 18.48it/s]\u001b[A\n",
      "606it [00:31, 18.36it/s]\u001b[A\n",
      "608it [00:31, 18.50it/s]\u001b[A\n",
      "610it [00:31, 18.26it/s]\u001b[A\n",
      "612it [00:31, 18.35it/s]\u001b[A\n",
      "614it [00:31, 18.34it/s]\u001b[A\n",
      "616it [00:31, 18.26it/s]\u001b[A\n",
      "619it [00:31, 18.96it/s]\u001b[A\n",
      "621it [00:31, 18.80it/s]\u001b[A\n",
      "624it [00:32, 19.34it/s]\u001b[A\n",
      "626it [00:32, 19.44it/s]\u001b[A\n",
      "628it [00:32, 19.53it/s]\u001b[A\n",
      "630it [00:32, 19.47it/s]\u001b[A\n",
      "632it [00:32, 18.93it/s]\u001b[A\n",
      "634it [00:32, 18.96it/s]\u001b[A\n",
      "636it [00:32, 19.19it/s]\u001b[A\n",
      "638it [00:32, 19.16it/s]\u001b[A\n",
      "640it [00:32, 19.15it/s]\u001b[A\n",
      "643it [00:33, 19.61it/s]\u001b[A\n",
      "645it [00:33, 19.31it/s]\u001b[A\n",
      "647it [00:33, 19.00it/s]\u001b[A\n",
      "650it [00:33, 19.53it/s]\u001b[A\n",
      "652it [00:33, 19.34it/s]\u001b[A\n",
      "655it [00:33, 19.63it/s]\u001b[A\n",
      "657it [00:33, 18.31it/s]\u001b[A\n",
      "659it [00:33, 18.41it/s]\u001b[A\n",
      "661it [00:34, 18.25it/s]\u001b[A\n",
      "663it [00:34, 17.30it/s]\u001b[A\n",
      "666it [00:34, 18.09it/s]\u001b[A\n",
      "668it [00:34, 17.59it/s]\u001b[A\n",
      "670it [00:34, 17.81it/s]\u001b[A\n",
      "673it [00:34, 18.95it/s]\u001b[A\n",
      "675it [00:34, 18.55it/s]\u001b[A\n",
      "677it [00:34, 18.83it/s]\u001b[A\n",
      "679it [00:34, 18.81it/s]\u001b[A\n",
      "682it [00:35, 19.27it/s]\u001b[A\n",
      "685it [00:35, 19.70it/s]\u001b[A\n",
      "688it [00:35, 20.01it/s]\u001b[A\n",
      "691it [00:35, 19.61it/s]\u001b[A\n",
      "693it [00:35, 19.08it/s]\u001b[A\n",
      "695it [00:35, 19.19it/s]\u001b[A\n",
      "697it [00:35, 19.03it/s]\u001b[A\n",
      "699it [00:35, 19.14it/s]\u001b[A\n",
      "701it [00:36, 19.01it/s]\u001b[A\n",
      "704it [00:36, 19.74it/s]\u001b[A\n",
      "706it [00:36, 19.24it/s]\u001b[A\n",
      "708it [00:36, 19.19it/s]\u001b[A\n",
      "710it [00:36, 19.10it/s]\u001b[A\n",
      "712it [00:36, 19.32it/s]\u001b[A\n",
      "714it [00:36, 18.72it/s]\u001b[A\n",
      "716it [00:36, 18.83it/s]\u001b[A\n",
      "718it [00:36, 18.36it/s]\u001b[A\n",
      "721it [00:37, 19.16it/s]\u001b[A\n",
      "723it [00:37, 19.15it/s]\u001b[A\n",
      "725it [00:37, 18.83it/s]\u001b[A\n",
      "727it [00:37, 18.96it/s]\u001b[A\n",
      "729it [00:37, 19.02it/s]\u001b[A\n",
      "732it [00:37, 19.46it/s]\u001b[A\n",
      "734it [00:37, 19.49it/s]\u001b[A\n",
      "736it [00:37, 19.51it/s]\u001b[A\n",
      "738it [00:38, 18.59it/s]\u001b[A\n",
      "741it [00:38, 19.20it/s]\u001b[A\n",
      "743it [00:38, 19.32it/s]\u001b[A\n",
      "745it [00:38, 19.28it/s]\u001b[A\n",
      "747it [00:38, 19.04it/s]\u001b[A\n",
      "749it [00:38, 18.84it/s]\u001b[A\n",
      "752it [00:38, 19.31it/s]\u001b[A\n",
      "754it [00:38, 19.50it/s]\u001b[A\n",
      "756it [00:38, 19.62it/s]\u001b[A\n",
      "758it [00:39, 19.17it/s]\u001b[A\n",
      "760it [00:39, 19.33it/s]\u001b[A\n",
      "762it [00:39, 19.52it/s]\u001b[A\n",
      "764it [00:39, 19.58it/s]\u001b[A\n",
      "766it [00:39, 19.52it/s]\u001b[A\n",
      "768it [00:39, 19.27it/s]\u001b[A\n",
      "770it [00:39, 19.19it/s]\u001b[A\n",
      "772it [00:39, 18.90it/s]\u001b[A\n",
      "774it [00:39, 19.08it/s]\u001b[A\n",
      "777it [00:40, 19.64it/s]\u001b[A\n",
      "779it [00:40, 19.12it/s]\u001b[A\n",
      "782it [00:40, 19.57it/s]\u001b[A\n",
      "784it [00:40, 19.34it/s]\u001b[A\n",
      "786it [00:40, 18.66it/s]\u001b[A\n",
      "788it [00:40, 17.96it/s]\u001b[A\n",
      "790it [00:40, 17.94it/s]\u001b[A\n",
      "792it [00:40, 18.15it/s]\u001b[A\n",
      "795it [00:40, 18.84it/s]\u001b[A\n",
      "797it [00:41, 18.91it/s]\u001b[A\n",
      "799it [00:41, 19.00it/s]\u001b[A\n",
      "801it [00:41, 18.56it/s]\u001b[A\n",
      "803it [00:41, 18.52it/s]\u001b[A\n",
      "805it [00:41, 18.90it/s]\u001b[A\n",
      "807it [00:41, 18.98it/s]\u001b[A\n",
      "809it [00:41, 19.03it/s]\u001b[A\n",
      "811it [00:41, 18.68it/s]\u001b[A\n",
      "813it [00:41, 18.51it/s]\u001b[A\n",
      "815it [00:42, 18.45it/s]\u001b[A\n",
      "817it [00:42, 18.17it/s]\u001b[A\n",
      "819it [00:42, 18.18it/s]\u001b[A\n",
      "821it [00:42, 18.32it/s]\u001b[A\n",
      "823it [00:42, 18.00it/s]\u001b[A\n",
      "826it [00:42, 18.82it/s]\u001b[A\n",
      "828it [00:42, 19.03it/s]\u001b[A\n",
      "830it [00:42, 19.27it/s]\u001b[A\n",
      "833it [00:42, 19.78it/s]\u001b[A\n",
      "836it [00:43, 19.63it/s]\u001b[A\n",
      "838it [00:43, 19.61it/s]\u001b[A\n",
      "840it [00:43, 19.70it/s]\u001b[A\n",
      "842it [00:43, 19.55it/s]\u001b[A\n",
      "845it [00:43, 19.39it/s]\u001b[A\n",
      "847it [00:43, 19.29it/s]\u001b[A\n",
      "850it [00:43, 19.84it/s]\u001b[A\n",
      "852it [00:43, 19.50it/s]\u001b[A\n",
      "854it [00:44, 18.24it/s]\u001b[A\n",
      "856it [00:44, 17.95it/s]\u001b[A\n",
      "858it [00:44, 18.36it/s]\u001b[A\n",
      "861it [00:44, 18.91it/s]\u001b[A\n",
      "864it [00:44, 19.15it/s]\u001b[A\n",
      "866it [00:44, 19.11it/s]\u001b[A\n",
      "868it [00:44, 19.02it/s]\u001b[A\n",
      "870it [00:44, 19.10it/s]\u001b[A\n",
      "872it [00:45, 18.88it/s]\u001b[A\n",
      "874it [00:45, 17.21it/s]\u001b[A\n",
      "876it [00:45, 17.90it/s]\u001b[A\n",
      "879it [00:45, 18.93it/s]\u001b[A\n",
      "881it [00:45, 18.87it/s]\u001b[A\n",
      "883it [00:45, 18.83it/s]\u001b[A\n",
      "885it [00:45, 18.99it/s]\u001b[A\n",
      "887it [00:45, 18.90it/s]\u001b[A\n",
      "889it [00:45, 18.15it/s]\u001b[A\n",
      "891it [00:46, 18.25it/s]\u001b[A\n",
      "893it [00:46, 18.56it/s]\u001b[A\n",
      "895it [00:46, 18.44it/s]\u001b[A\n",
      "897it [00:46, 18.74it/s]\u001b[A\n",
      "899it [00:46, 18.80it/s]\u001b[A\n",
      "901it [00:46, 18.89it/s]\u001b[A\n",
      "903it [00:46, 18.63it/s]\u001b[A\n",
      "905it [00:46, 18.39it/s]\u001b[A\n",
      "908it [00:46, 19.11it/s]\u001b[A\n",
      "910it [00:47, 19.37it/s]\u001b[A\n",
      "912it [00:47, 19.24it/s]\u001b[A\n",
      "914it [00:47, 18.84it/s]\u001b[A\n",
      "916it [00:47, 18.42it/s]\u001b[A\n",
      "918it [00:47, 18.64it/s]\u001b[A\n",
      "920it [00:47, 18.95it/s]\u001b[A\n",
      "922it [00:47, 18.51it/s]\u001b[A\n",
      "924it [00:47, 18.11it/s]\u001b[A\n",
      "927it [00:47, 18.89it/s]\u001b[A\n",
      "930it [00:48, 19.35it/s]\u001b[A\n",
      "932it [00:48, 18.83it/s]\u001b[A\n",
      "934it [00:48, 18.65it/s]\u001b[A\n",
      "936it [00:48, 17.55it/s]\u001b[A\n",
      "938it [00:48, 17.51it/s]\u001b[A\n",
      "940it [00:48, 18.04it/s]\u001b[A\n",
      "942it [00:48, 17.93it/s]\u001b[A\n",
      "944it [00:48, 18.38it/s]\u001b[A\n",
      "946it [00:49, 18.18it/s]\u001b[A\n",
      "948it [00:49, 17.97it/s]\u001b[A\n",
      "950it [00:49, 18.47it/s]\u001b[A\n",
      "952it [00:49, 18.30it/s]\u001b[A\n",
      "955it [00:49, 18.93it/s]\u001b[A\n",
      "957it [00:49, 19.10it/s]\u001b[A\n",
      "959it [00:49, 18.28it/s]\u001b[A\n",
      "961it [00:49, 17.81it/s]\u001b[A\n",
      "963it [00:49, 18.07it/s]\u001b[A\n",
      "965it [00:50, 18.36it/s]\u001b[A\n",
      "967it [00:50, 18.65it/s]\u001b[A\n",
      "969it [00:50, 18.57it/s]\u001b[A\n",
      "971it [00:50, 18.04it/s]\u001b[A\n",
      "974it [00:50, 18.76it/s]\u001b[A\n",
      "977it [00:50, 19.29it/s]\u001b[A\n",
      "979it [00:50, 19.12it/s]\u001b[A\n",
      "981it [00:50, 18.87it/s]\u001b[A\n",
      "983it [00:50, 19.01it/s]\u001b[A\n",
      "985it [00:51, 18.79it/s]\u001b[A\n",
      "987it [00:51, 18.96it/s]\u001b[A\n",
      "989it [00:51, 19.11it/s]\u001b[A\n",
      "991it [00:51, 17.54it/s]\u001b[A\n",
      "993it [00:51, 18.06it/s]\u001b[A\n",
      "995it [00:51, 18.32it/s]\u001b[A\n",
      "997it [00:51, 18.62it/s]\u001b[A\n",
      "1000it [00:51, 19.12it/s]\u001b[A\n",
      "1002it [00:51, 19.16it/s]\u001b[A\n",
      "1005it [00:52, 19.43it/s]\u001b[A\n",
      "1007it [00:52, 17.99it/s]\u001b[A\n",
      "1010it [00:52, 18.54it/s]\u001b[A\n",
      "1012it [00:52, 18.63it/s]\u001b[A\n",
      "1014it [00:52, 18.63it/s]\u001b[A\n",
      "1016it [00:52, 18.98it/s]\u001b[A\n",
      "1018it [00:52, 17.72it/s]\u001b[A\n",
      "1021it [00:53, 18.73it/s]\u001b[A\n",
      "1023it [00:53, 18.49it/s]\u001b[A\n",
      "1025it [00:53, 18.68it/s]\u001b[A\n",
      "1027it [00:53, 18.99it/s]\u001b[A\n",
      "1029it [00:53, 18.74it/s]\u001b[A\n",
      "1031it [00:53, 19.08it/s]\u001b[A\n",
      "1033it [00:53, 19.20it/s]\u001b[A\n",
      "1035it [00:53, 18.80it/s]\u001b[A\n",
      "1037it [00:53, 19.05it/s]\u001b[A\n",
      "1039it [00:53, 19.01it/s]\u001b[A\n",
      "1042it [00:54, 19.29it/s]\u001b[A\n",
      "1044it [00:54, 19.25it/s]\u001b[A\n",
      "1046it [00:54, 19.32it/s]\u001b[A\n",
      "1048it [00:54, 19.01it/s]\u001b[A\n",
      "1050it [00:54, 18.75it/s]\u001b[A\n",
      "1052it [00:54, 18.97it/s]\u001b[A\n",
      "1054it [00:54, 18.51it/s]\u001b[A\n",
      "1056it [00:54, 18.29it/s]\u001b[A\n",
      "1058it [00:54, 18.61it/s]\u001b[A\n",
      "1060it [00:55, 18.77it/s]\u001b[A\n",
      "1062it [00:55, 18.92it/s]\u001b[A\n",
      "1064it [00:55, 19.22it/s]\u001b[A\n",
      "1067it [00:55, 19.35it/s]\u001b[A\n",
      "1069it [00:55, 18.79it/s]\u001b[A\n",
      "1071it [00:55, 18.19it/s]\u001b[A\n",
      "1073it [00:55, 18.31it/s]\u001b[A\n",
      "1075it [00:55, 18.23it/s]\u001b[A\n",
      "1077it [00:55, 17.95it/s]\u001b[A\n",
      "1079it [00:56, 18.14it/s]\u001b[A\n",
      "1081it [00:56, 18.25it/s]\u001b[A\n",
      "1083it [00:56, 18.62it/s]\u001b[A\n",
      "1086it [00:56, 19.07it/s]\u001b[A\n",
      "1088it [00:56, 18.78it/s]\u001b[A\n",
      "1090it [00:56, 18.71it/s]\u001b[A\n",
      "1092it [00:56, 18.68it/s]\u001b[A\n",
      "1095it [00:56, 19.02it/s]\u001b[A\n",
      "1097it [00:57, 18.51it/s]\u001b[A\n",
      "1100it [00:57, 19.31it/s]\u001b[A\n",
      "1102it [00:57, 19.32it/s]\u001b[A\n",
      "1104it [00:57, 19.39it/s]\u001b[A\n",
      "1106it [00:57, 19.10it/s]\u001b[A\n",
      "1108it [00:57, 19.02it/s]\u001b[A\n",
      "1111it [00:57, 19.60it/s]\u001b[A\n",
      "1113it [00:57, 19.39it/s]\u001b[A\n",
      "1116it [00:57, 20.00it/s]\u001b[A\n",
      "1119it [00:58, 19.84it/s]\u001b[A\n",
      "1122it [00:58, 20.32it/s]\u001b[A\n",
      "1125it [00:58, 20.53it/s]\u001b[A\n",
      "1128it [00:58, 19.86it/s]\u001b[A\n",
      "1130it [00:58, 19.44it/s]\u001b[A\n",
      "1132it [00:58, 19.08it/s]\u001b[A\n",
      "1135it [00:58, 19.45it/s]\u001b[A\n",
      "1138it [00:59, 19.79it/s]\u001b[A\n",
      "1140it [00:59, 19.78it/s]\u001b[A\n",
      "1142it [00:59, 19.77it/s]\u001b[A\n",
      "1144it [00:59, 19.83it/s]\u001b[A\n",
      "1146it [00:59, 19.27it/s]\u001b[A\n",
      "1149it [00:59, 19.94it/s]\u001b[A\n",
      "1152it [00:59, 20.08it/s]\u001b[A\n",
      "1155it [00:59, 20.25it/s]\u001b[A\n",
      "1158it [01:00, 20.41it/s]\u001b[A\n",
      "1161it [01:00, 20.32it/s]\u001b[A\n",
      "1164it [01:00, 20.24it/s]\u001b[A\n",
      "1167it [01:00, 19.98it/s]\u001b[A\n",
      "1170it [01:00, 19.68it/s]\u001b[A\n",
      "1172it [01:00, 19.70it/s]\u001b[A\n",
      "1174it [01:00, 19.71it/s]\u001b[A\n",
      "1176it [01:01, 19.64it/s]\u001b[A\n",
      "1179it [01:01, 19.74it/s]\u001b[A\n",
      "1181it [01:01, 19.56it/s]\u001b[A\n",
      "1183it [01:01, 19.47it/s]\u001b[A\n",
      "1185it [01:01, 19.14it/s]\u001b[A\n",
      "1187it [01:01, 19.28it/s]\u001b[A\n",
      "1189it [01:01, 19.35it/s]\u001b[A\n",
      "1192it [01:01, 19.90it/s]\u001b[A\n",
      "1194it [01:01, 18.95it/s]\u001b[A\n",
      "1197it [01:02, 19.38it/s]\u001b[A\n",
      "1199it [01:02, 19.10it/s]\u001b[A\n",
      "1201it [01:02, 19.15it/s]\u001b[A\n",
      "1203it [01:02, 18.64it/s]\u001b[A\n",
      "1205it [01:02, 18.70it/s]\u001b[A\n",
      "1207it [01:02, 18.99it/s]\u001b[A\n",
      "1210it [01:02, 19.37it/s]\u001b[A\n",
      "1212it [01:02, 19.18it/s]\u001b[A\n",
      "1214it [01:02, 19.36it/s]\u001b[A\n",
      "1216it [01:03, 19.45it/s]\u001b[A\n",
      "1218it [01:03, 19.52it/s]\u001b[A\n",
      "1220it [01:03, 19.41it/s]\u001b[A\n",
      "1222it [01:03, 19.14it/s]\u001b[A\n",
      "1224it [01:03, 19.34it/s]\u001b[A\n",
      "1226it [01:03, 19.16it/s]\u001b[A\n",
      "1228it [01:03, 18.60it/s]\u001b[A\n",
      "1231it [01:03, 19.21it/s]\u001b[A\n",
      "1234it [01:04, 19.61it/s]\u001b[A\n",
      "1236it [01:04, 19.19it/s]\u001b[A\n",
      "1238it [01:04, 19.24it/s]\u001b[A\n",
      "1241it [01:04, 19.87it/s]\u001b[A\n",
      "1243it [01:04, 18.00it/s]\u001b[A\n",
      "1245it [01:04, 18.47it/s]\u001b[A\n",
      "1247it [01:04, 18.60it/s]\u001b[A\n",
      "1249it [01:04, 18.91it/s]\u001b[A\n",
      "1251it [01:04, 18.85it/s]\u001b[A\n",
      "1253it [01:05, 18.91it/s]\u001b[A\n",
      "1256it [01:05, 19.38it/s]\u001b[A\n",
      "1258it [01:05, 19.50it/s]\u001b[A\n",
      "1261it [01:05, 19.94it/s]\u001b[A\n",
      "1264it [01:05, 19.78it/s]\u001b[A\n",
      "1266it [01:05, 19.55it/s]\u001b[A\n",
      "1268it [01:05, 19.26it/s]\u001b[A\n",
      "1270it [01:05, 18.99it/s]\u001b[A\n",
      "1272it [01:05, 19.11it/s]\u001b[A\n",
      "1275it [01:06, 19.63it/s]\u001b[A\n",
      "1278it [01:06, 19.33it/s]\u001b[A\n",
      "1280it [01:06, 18.67it/s]\u001b[A\n",
      "1282it [01:06, 18.63it/s]\u001b[A\n",
      "1285it [01:06, 19.11it/s]\u001b[A\n",
      "1287it [01:06, 18.99it/s]\u001b[A\n",
      "1289it [01:06, 19.00it/s]\u001b[A\n",
      "1291it [01:06, 18.78it/s]\u001b[A\n",
      "1293it [01:07, 18.74it/s]\u001b[A\n",
      "1295it [01:07, 18.84it/s]\u001b[A\n",
      "1297it [01:07, 18.85it/s]\u001b[A\n",
      "1299it [01:07, 19.09it/s]\u001b[A\n",
      "1301it [01:07, 19.25it/s]\u001b[A\n",
      "1303it [01:07, 19.34it/s]\u001b[A\n",
      "1305it [01:07, 18.05it/s]\u001b[A\n",
      "1307it [01:07, 18.51it/s]\u001b[A\n",
      "1309it [01:07, 18.41it/s]\u001b[A\n",
      "1311it [01:08, 18.72it/s]\u001b[A\n",
      "1313it [01:08, 18.99it/s]\u001b[A\n",
      "1316it [01:08, 19.72it/s]\u001b[A\n",
      "1318it [01:08, 19.45it/s]\u001b[A\n",
      "1320it [01:08, 19.19it/s]\u001b[A\n",
      "1322it [01:08, 18.78it/s]\u001b[A\n",
      "1324it [01:08, 18.14it/s]\u001b[A\n",
      "1326it [01:08, 18.11it/s]\u001b[A\n",
      "1329it [01:08, 18.84it/s]\u001b[A\n",
      "1332it [01:09, 19.04it/s]\u001b[A\n",
      "1335it [01:09, 19.63it/s]\u001b[A\n",
      "1337it [01:09, 19.49it/s]\u001b[A\n",
      "1339it [01:09, 19.04it/s]\u001b[A\n",
      "1341it [01:09, 19.22it/s]\u001b[A\n",
      "1344it [01:09, 19.19it/s]\u001b[A\n",
      "1346it [01:09, 19.41it/s]\u001b[A\n",
      "1348it [01:09, 19.29it/s]\u001b[A\n",
      "1350it [01:10, 19.11it/s]\u001b[A\n",
      "1352it [01:10, 19.32it/s]\u001b[A\n",
      "1354it [01:10, 19.06it/s]\u001b[A\n",
      "1357it [01:10, 18.98it/s]\u001b[A\n",
      "1359it [01:10, 18.68it/s]\u001b[A\n",
      "1362it [01:10, 19.29it/s]\u001b[A\n",
      "1364it [01:10, 19.05it/s]\u001b[A\n",
      "1366it [01:10, 19.18it/s]\u001b[A\n",
      "1368it [01:11, 18.83it/s]\u001b[A\n",
      "1370it [01:11, 19.07it/s]\u001b[A\n",
      "1372it [01:11, 18.80it/s]\u001b[A\n",
      "1375it [01:11, 19.24it/s]\u001b[A\n",
      "1377it [01:11, 19.10it/s]\u001b[A\n",
      "1380it [01:11, 19.75it/s]\u001b[A\n",
      "1382it [01:11, 19.15it/s]\u001b[A\n",
      "1384it [01:11, 18.88it/s]\u001b[A\n",
      "1386it [01:11, 19.08it/s]\u001b[A\n",
      "1388it [01:12, 19.13it/s]\u001b[A\n",
      "1390it [01:12, 19.27it/s]\u001b[A\n",
      "1392it [01:12, 18.86it/s]\u001b[A\n",
      "1395it [01:12, 18.93it/s]\u001b[A\n",
      "1397it [01:12, 18.70it/s]\u001b[A\n",
      "1399it [01:12, 18.56it/s]\u001b[A\n",
      "1401it [01:12, 17.69it/s]\u001b[A\n",
      "1403it [01:12, 17.79it/s]\u001b[A\n",
      "1405it [01:12, 18.03it/s]\u001b[A\n",
      "1407it [01:13, 18.50it/s]\u001b[A\n",
      "1409it [01:13, 18.84it/s]\u001b[A\n",
      "1411it [01:13, 18.40it/s]\u001b[A\n",
      "1414it [01:13, 18.93it/s]\u001b[A\n",
      "1416it [01:13, 19.03it/s]\u001b[A\n",
      "1419it [01:13, 19.89it/s]\u001b[A\n",
      "1422it [01:13, 19.53it/s]\u001b[A\n",
      "1424it [01:13, 18.85it/s]\u001b[A\n",
      "1426it [01:14, 18.33it/s]\u001b[A\n",
      "1428it [01:14, 18.02it/s]\u001b[A\n",
      "1430it [01:14, 18.16it/s]\u001b[A\n",
      "1433it [01:14, 19.09it/s]\u001b[A\n",
      "1435it [01:14, 19.21it/s]\u001b[A\n",
      "1437it [01:14, 19.31it/s]\u001b[A\n",
      "1440it [01:14, 19.83it/s]\u001b[A\n",
      "1442it [01:14, 19.47it/s]\u001b[A\n",
      "1445it [01:15, 19.57it/s]\u001b[A\n",
      "1447it [01:15, 19.60it/s]\u001b[A\n",
      "1449it [01:15, 19.15it/s]\u001b[A\n",
      "1451it [01:15, 19.20it/s]\u001b[A\n",
      "1453it [01:15, 19.16it/s]\u001b[A\n",
      "1455it [01:15, 18.93it/s]\u001b[A\n",
      "1457it [01:15, 19.13it/s]\u001b[A\n",
      "1460it [01:15, 19.65it/s]\u001b[A\n",
      "1462it [01:15, 19.00it/s]\u001b[A\n",
      "1464it [01:16, 18.64it/s]\u001b[A\n",
      "1466it [01:16, 18.81it/s]\u001b[A\n",
      "1468it [01:16, 19.06it/s]\u001b[A\n",
      "1470it [01:16, 18.76it/s]\u001b[A\n",
      "1472it [01:16, 18.77it/s]\u001b[A\n",
      "1475it [01:16, 19.38it/s]\u001b[A\n",
      "1477it [01:16, 19.34it/s]\u001b[A\n",
      "1480it [01:16, 19.68it/s]\u001b[A\n",
      "1482it [01:16, 19.23it/s]\u001b[A\n",
      "1484it [01:17, 19.08it/s]\u001b[A\n",
      "1486it [01:17, 18.24it/s]\u001b[A\n",
      "1488it [01:17, 18.56it/s]\u001b[A\n",
      "1490it [01:17, 18.92it/s]\u001b[A\n",
      "1492it [01:17, 18.51it/s]\u001b[A\n",
      "1495it [01:17, 19.47it/s]\u001b[A\n",
      "1498it [01:17, 19.89it/s]\u001b[A\n",
      "1501it [01:17, 19.69it/s]\u001b[A\n",
      "1503it [01:18, 19.27it/s]\u001b[A\n",
      "1506it [01:18, 19.60it/s]\u001b[A\n",
      "1508it [01:18, 19.49it/s]\u001b[A\n",
      "1511it [01:18, 20.02it/s]\u001b[A\n",
      "1514it [01:18, 20.20it/s]\u001b[A\n",
      "1517it [01:18, 20.29it/s]\u001b[A\n",
      "1520it [01:18, 20.38it/s]\u001b[A\n",
      "1523it [01:19, 20.67it/s]\u001b[A\n",
      "1526it [01:19, 19.79it/s]\u001b[A\n",
      "1530it [01:19, 19.28it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 19.06it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train results:\n",
      "Mean square error: 0.21213\n",
      "Mean absolute error: 0.37878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [00:00, 18.28it/s]\u001b[A\n",
      "6it [00:00, 18.65it/s]\u001b[A\n",
      "9it [00:00, 19.18it/s]\u001b[A\n",
      "11it [00:00, 19.16it/s]\u001b[A\n",
      "13it [00:00, 18.92it/s]\u001b[A\n",
      "16it [00:00, 18.71it/s]\u001b[A\n",
      "18it [00:00, 18.87it/s]\u001b[A\n",
      "20it [00:01, 19.07it/s]\u001b[A\n",
      "22it [00:01, 19.27it/s]\u001b[A\n",
      "24it [00:01, 19.03it/s]\u001b[A\n",
      "27it [00:01, 19.78it/s]\u001b[A\n",
      "29it [00:01, 19.61it/s]\u001b[A\n",
      "31it [00:01, 18.59it/s]\u001b[A\n",
      "33it [00:01, 18.52it/s]\u001b[A\n",
      "35it [00:01, 18.04it/s]\u001b[A\n",
      "37it [00:01, 18.47it/s]\u001b[A\n",
      "39it [00:02, 18.71it/s]\u001b[A\n",
      "41it [00:02, 18.53it/s]\u001b[A\n",
      "44it [00:02, 18.94it/s]\u001b[A\n",
      "46it [00:02, 19.24it/s]\u001b[A\n",
      "49it [00:02, 19.77it/s]\u001b[A\n",
      "51it [00:02, 19.31it/s]\u001b[A\n",
      "54it [00:02, 19.82it/s]\u001b[A\n",
      "57it [00:02, 19.94it/s]\u001b[A\n",
      "60it [00:03, 19.91it/s]\u001b[A\n",
      "62it [00:03, 19.58it/s]\u001b[A\n",
      "64it [00:03, 19.29it/s]\u001b[A\n",
      "67it [00:03, 19.70it/s]\u001b[A\n",
      "69it [00:03, 19.45it/s]\u001b[A\n",
      "71it [00:03, 19.27it/s]\u001b[A\n",
      "74it [00:03, 19.78it/s]\u001b[A\n",
      "76it [00:03, 19.11it/s]\u001b[A\n",
      "78it [00:04, 19.01it/s]\u001b[A\n",
      "80it [00:04, 18.49it/s]\u001b[A\n",
      "83it [00:04, 19.18it/s]\u001b[A\n",
      "85it [00:04, 19.30it/s]\u001b[A\n",
      "88it [00:04, 19.70it/s]\u001b[A\n",
      "90it [00:04, 19.56it/s]\u001b[A\n",
      "92it [00:04, 18.87it/s]\u001b[A\n",
      "94it [00:04, 18.83it/s]\u001b[A\n",
      "96it [00:04, 18.62it/s]\u001b[A\n",
      "98it [00:05, 18.92it/s]\u001b[A\n",
      "100it [00:05, 18.75it/s]\u001b[A\n",
      "103it [00:05, 19.19it/s]\u001b[A\n",
      "105it [00:05, 19.26it/s]\u001b[A\n",
      "107it [00:05, 19.11it/s]\u001b[A\n",
      "110it [00:05, 19.02it/s]\u001b[A\n",
      "112it [00:05, 18.86it/s]\u001b[A\n",
      "115it [00:05, 19.35it/s]\u001b[A\n",
      "117it [00:06, 18.59it/s]\u001b[A\n",
      "119it [00:06, 18.92it/s]\u001b[A\n",
      "122it [00:06, 18.39it/s]\u001b[A\n",
      "125it [00:06, 19.15it/s]\u001b[A\n",
      "128it [00:06, 19.73it/s]\u001b[A\n",
      "130it [00:06, 19.57it/s]\u001b[A\n",
      "132it [00:06, 18.59it/s]\u001b[A\n",
      "134it [00:06, 18.95it/s]\u001b[A\n",
      "136it [00:07, 19.12it/s]\u001b[A\n",
      "138it [00:07, 18.78it/s]\u001b[A\n",
      "140it [00:07, 19.05it/s]\u001b[A\n",
      "142it [00:07, 19.13it/s]\u001b[A\n",
      "144it [00:07, 18.81it/s]\u001b[A\n",
      "146it [00:07, 18.62it/s]\u001b[A\n",
      "148it [00:07, 18.54it/s]\u001b[A\n",
      "150it [00:07, 18.37it/s]\u001b[A\n",
      "153it [00:07, 18.99it/s]\u001b[A\n",
      "155it [00:08, 18.99it/s]\u001b[A\n",
      "157it [00:08, 18.77it/s]\u001b[A\n",
      "160it [00:08, 19.08it/s]\u001b[A\n",
      "162it [00:08, 19.32it/s]\u001b[A\n",
      "164it [00:08, 19.23it/s]\u001b[A\n",
      "167it [00:08, 19.80it/s]\u001b[A\n",
      "169it [00:08, 19.44it/s]\u001b[A\n",
      "171it [00:08, 19.09it/s]\u001b[A\n",
      "173it [00:09, 19.11it/s]\u001b[A\n",
      "175it [00:09, 18.58it/s]\u001b[A\n",
      "177it [00:09, 18.66it/s]\u001b[A\n",
      "180it [00:09, 19.27it/s]\u001b[A\n",
      "183it [00:09, 19.62it/s]\u001b[A\n",
      "185it [00:09, 19.42it/s]\u001b[A\n",
      "188it [00:09, 19.88it/s]\u001b[A\n",
      "190it [00:09, 18.88it/s]\u001b[A\n",
      "193it [00:10, 19.37it/s]\u001b[A\n",
      "195it [00:10, 18.77it/s]\u001b[A\n",
      "197it [00:10, 19.07it/s]\u001b[A\n",
      "200it [00:10, 19.66it/s]\u001b[A\n",
      "202it [00:10, 18.96it/s]\u001b[A\n",
      "204it [00:10, 19.07it/s]\u001b[A\n",
      "206it [00:10, 18.83it/s]\u001b[A\n",
      "209it [00:10, 19.15it/s]\u001b[A\n",
      "212it [00:11, 19.74it/s]\u001b[A\n",
      "214it [00:11, 19.23it/s]\u001b[A\n",
      "217it [00:11, 19.68it/s]\u001b[A\n",
      "219it [00:11, 19.63it/s]\u001b[A\n",
      "221it [00:11, 19.73it/s]\u001b[A\n",
      "223it [00:11, 19.33it/s]\u001b[A\n",
      "226it [00:11, 19.83it/s]\u001b[A\n",
      "229it [00:11, 19.40it/s]\u001b[A\n",
      "232it [00:12, 18.81it/s]\u001b[A\n",
      "235it [00:12, 19.32it/s]\u001b[A\n",
      "238it [00:12, 19.84it/s]\u001b[A\n",
      "241it [00:12, 20.30it/s]\u001b[A\n",
      "244it [00:12, 20.22it/s]\u001b[A\n",
      "247it [00:12, 20.15it/s]\u001b[A\n",
      "250it [00:12, 18.86it/s]\u001b[A\n",
      "252it [00:13, 18.34it/s]\u001b[A\n",
      "255it [00:13, 19.05it/s]\u001b[A\n",
      "257it [00:13, 19.32it/s]\u001b[A\n",
      "259it [00:13, 19.14it/s]\u001b[A\n",
      "261it [00:13, 19.26it/s]\u001b[A\n",
      "264it [00:13, 19.84it/s]\u001b[A\n",
      "266it [00:13, 19.63it/s]\u001b[A\n",
      "269it [00:13, 19.53it/s]\u001b[A\n",
      "272it [00:14, 19.95it/s]\u001b[A\n",
      "275it [00:14, 20.34it/s]\u001b[A\n",
      "278it [00:14, 20.81it/s]\u001b[A\n",
      "281it [00:14, 20.51it/s]\u001b[A\n",
      "284it [00:14, 20.90it/s]\u001b[A\n",
      "287it [00:14, 20.45it/s]\u001b[A\n",
      "290it [00:14, 19.82it/s]\u001b[A\n",
      "292it [00:15, 18.19it/s]\u001b[A\n",
      "294it [00:15, 18.58it/s]\u001b[A\n",
      "296it [00:15, 18.77it/s]\u001b[A\n",
      "299it [00:15, 19.56it/s]\u001b[A\n",
      "301it [00:15, 19.53it/s]\u001b[A\n",
      "303it [00:15, 19.66it/s]\u001b[A\n",
      "305it [00:15, 18.36it/s]\u001b[A\n",
      "307it [00:15, 18.47it/s]\u001b[A\n",
      "309it [00:15, 18.35it/s]\u001b[A\n",
      "311it [00:16, 18.47it/s]\u001b[A\n",
      "314it [00:16, 19.24it/s]\u001b[A\n",
      "317it [00:16, 19.74it/s]\u001b[A\n",
      "320it [00:16, 20.17it/s]\u001b[A\n",
      "323it [00:16, 20.29it/s]\u001b[A\n",
      "326it [00:16, 20.29it/s]\u001b[A\n",
      "329it [00:16, 20.04it/s]\u001b[A\n",
      "332it [00:17, 19.63it/s]\u001b[A\n",
      "335it [00:17, 19.90it/s]\u001b[A\n",
      "337it [00:17, 19.81it/s]\u001b[A\n",
      "339it [00:17, 19.75it/s]\u001b[A\n",
      "341it [00:17, 19.71it/s]\u001b[A\n",
      "344it [00:17, 20.17it/s]\u001b[A\n",
      "347it [00:17, 20.52it/s]\u001b[A\n",
      "350it [00:17, 20.82it/s]\u001b[A\n",
      "353it [00:18, 20.29it/s]\u001b[A\n",
      "356it [00:18, 20.53it/s]\u001b[A\n",
      "359it [00:18, 20.47it/s]\u001b[A\n",
      "362it [00:18, 19.75it/s]\u001b[A\n",
      "364it [00:18, 18.90it/s]\u001b[A\n",
      "366it [00:18, 19.21it/s]\u001b[A\n",
      "369it [00:18, 19.67it/s]\u001b[A\n",
      "371it [00:19, 19.60it/s]\u001b[A\n",
      "373it [00:19, 19.26it/s]\u001b[A\n",
      "375it [00:19, 19.37it/s]\u001b[A\n",
      "377it [00:19, 19.22it/s]\u001b[A\n",
      "379it [00:19, 19.25it/s]\u001b[A\n",
      "383it [00:19, 19.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val results:\n",
      "Mean square error: 0.21690\n",
      "Mean absolute error: 0.38205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "batch_size=128\n",
    "def print_metrics(model, data, batch_size=batch_size, name=\"\", **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
    "        batch = (\n",
    "            torch.tensor(batch_x['FullDescription'], dtype=torch.long).to(device),\n",
    "            torch.tensor(batch_x['Title'], dtype=torch.long).to(device),\n",
    "            torch.tensor(batch_x['Categorical'], dtype=torch.float).to(device)\n",
    "        )\n",
    "        batch_pred = model(batch)[:, 0].detach().cpu().numpy()\n",
    "        \n",
    "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
    "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
    "        num_samples += len(batch_y)\n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
    "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
    "    return squared_error, abs_error\n",
    "    \n",
    "print_metrics(model, data_train, name='Train')\n",
    "print_metrics(model, data_val, name='Val');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sB_iq0yimfAu"
   },
   "outputs": [],
   "source": [
    "1530it [00:48, 31.41it/s]\n",
    "4it [00:00, 31.49it/s]Train results:\n",
    "Mean square error: 0.27277\n",
    "Mean absolute error: 0.37702\n",
    "383it [00:12, 31.27it/s]Val results:\n",
    "Mean square error: 0.27143\n",
    "Mean absolute error: 0.37646"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J14754K2Urt-"
   },
   "outputs": [],
   "source": [
    "class ThreeInputsNet(nn.Module):\n",
    "    def __init__(self, n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_), hid_size=64):\n",
    "        super(TwoInputsNet, self).__init__()\n",
    "        self.title_emb = nn.Embedding(n_tokens, embedding_dim=hid_size)\n",
    "        # <YOUR CODE HERE>        \n",
    "        \n",
    "        self.full_emb = nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size)\n",
    "        # <YOUR CODE HERE>\n",
    "        \n",
    "        self.category_out = # <YOUR CODE HERE>\n",
    "        \n",
    "\n",
    "    def forward(self, whole_input):\n",
    "        input1, input2, input3 = whole_input\n",
    "        title_beg = self.title_emb(input1).permute((0, 2, 1))\n",
    "        title = # <YOUR CODE HERE>\n",
    "        \n",
    "        full_beg = self.full_emb(input2).permute((0, 2, 1))\n",
    "        full = # <YOUR CODE HERE>        \n",
    "        \n",
    "        category = # <YOUR CODE HERE>        \n",
    "        \n",
    "        concatenated = torch.cat(\n",
    "            [\n",
    "            title.view(title.size(0), -1),\n",
    "            full.view(full.size(0), -1),\n",
    "            category.view(category.size(0), -1)\n",
    "            ],\n",
    "            dim=1)\n",
    "        \n",
    "        out = # <YOUR CODE HERE>\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vOeBzWotUrt_"
   },
   "source": [
    "### Bonus area 2: comparing RNN to CNN\n",
    "Try implementing simple RNN (or LSTM) and applying it to this task. Compare the quality/performance of these networks. \n",
    "*Hint: try to build networks with ~same number of paremeters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IPJ9Gg_pUrt_"
   },
   "outputs": [],
   "source": [
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RsSvsN8oUruE"
   },
   "source": [
    "### Bonus area 3: fixing the data leaks\n",
    "Fix the data leak we ignored in the beginning of the __Deep Learning part__. Compare results with and without data leaks using same architectures and training time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0G6UAWpRUruE"
   },
   "outputs": [],
   "source": [
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hpbvre6rUruF"
   },
   "source": [
    "__Terrible start-up idea #1962:__ make a tool that automaticaly rephrases your job description (or CV) to meet salary expectations :)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "week04_practice_CNN_for_texts__from_class.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
